{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf3c824-0822-4c01-8436-fe21d75df9cd",
   "metadata": {},
   "source": [
    "# Environment & basic diagnostics (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd66bb-42f1-44e3-ab7c-24d0bf02a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "import numpy as np\n",
    "\n",
    "print(\"Python  :\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"NumPy   :\", np.__version__)\n",
    "\n",
    "# Optional: TensorFlow GPU memory growth (only if you really use TF later)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"TF GPUs  : {len(gpus)} (memory growth enabled)\")\n",
    "    else:\n",
    "        print(\"TF GPUs  : none\")\n",
    "except Exception as e:\n",
    "    print(f\"TensorFlow not used / not available ({e})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2dbda5-a437-4967-b2dc-d7b18f17c0c0",
   "metadata": {},
   "source": [
    "# Config & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed5c10-7a55-47a2-895b-aaf6a253483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Root folder: parent contains subfolders = class names\n",
    "DATA_DIR = Path(\"/workspace/masaboe_gmail.com/aboe/keris/baselineOriginalNoBG/pamor\")\n",
    "\n",
    "# Output folder for .npy\n",
    "OUT_NPY_DIR = Path(\"/workspace/masaboe_gmail.com/aboe/keris/baselineOriginalNoBG/PAMOR_/npy\")\n",
    "OUT_NPY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Image processing\n",
    "TARGET_SIZE = (128, 128)     # (W, H) for PIL, but we will use consistently\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "# Splits\n",
    "RANDOM_SEED = 42\n",
    "TRAIN_FRAC = 0.77            # -> remaining 0.23 will be split into val/test (0.115/0.115)\n",
    "VAL_FRAC_OF_TEMP = 0.5       # half of temp to val, half to test\n",
    "\n",
    "print(\"DATA_DIR    :\", DATA_DIR)\n",
    "print(\"OUT_NPY_DIR :\", OUT_NPY_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495c4d8-5c40-4cea-9fed-975bcd3f3487",
   "metadata": {},
   "source": [
    "# Inspect image size variability per class (optional but nice for appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586b854-dd82-40b8-b967-6d3520261ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def check_image_sizes_per_class(root: Path) -> dict[str, list[tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Returns a dict: class_name -> sorted list of unique (W, H) sizes.\n",
    "    \"\"\"\n",
    "    report = {}\n",
    "    for class_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        sizes = set()\n",
    "        for fp in class_dir.iterdir():\n",
    "            if fp.is_file() and fp.suffix.lower() in IMG_EXTS:\n",
    "                try:\n",
    "                    with Image.open(fp) as im:\n",
    "                        sizes.add(im.size)  # (W, H)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Failed reading: {fp} | {e}\")\n",
    "        report[class_dir.name] = sorted(sizes)\n",
    "    return report\n",
    "\n",
    "size_report = check_image_sizes_per_class(DATA_DIR)\n",
    "for k, v in size_report.items():\n",
    "    print(f\"Class '{k}': unique sizes = {v if v else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aebdf3-09c4-4a06-a78e-d8dbbc971c85",
   "metadata": {},
   "source": [
    "# Load images (RGB), resize, stack to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac6d8f-de69-4c81-9049-715ad969dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_images_rgb(root: Path, target_size=(128, 128)) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads images from:\n",
    "      root/class_name/*.ext\n",
    "\n",
    "    Returns:\n",
    "      X: uint8 array, shape (N, H, W, 3)\n",
    "      y: string array, shape (N,)\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    class_dirs = [p for p in root.iterdir() if p.is_dir()]\n",
    "    class_dirs.sort(key=lambda p: p.name)\n",
    "\n",
    "    for class_dir in class_dirs:\n",
    "        label = class_dir.name\n",
    "        files = [f for f in class_dir.iterdir() if f.is_file() and f.suffix.lower() in IMG_EXTS]\n",
    "        files.sort(key=lambda p: p.name)\n",
    "\n",
    "        for fp in files:\n",
    "            try:\n",
    "                img = Image.open(fp).convert(\"RGB\")\n",
    "                img = img.resize(target_size, resample=Image.Resampling.LANCZOS)\n",
    "                arr = np.asarray(img, dtype=np.uint8)  # (H, W, 3)\n",
    "                X_list.append(arr)\n",
    "                y_list.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Failed processing: {fp} | {e}\")\n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(f\"No valid images found under: {root}\")\n",
    "\n",
    "    X = np.stack(X_list, axis=0)          # (N, H, W, 3)\n",
    "    y = np.asarray(y_list, dtype=object)  # string labels\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_u8, y_str = load_images_rgb(DATA_DIR, target_size=TARGET_SIZE)\n",
    "\n",
    "print(\"X_u8:\", X_u8.shape, X_u8.dtype)\n",
    "print(\"y   :\", y_str.shape, y_str.dtype)\n",
    "print(\"Classes:\", sorted(set(y_str.tolist())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf605657-b682-416c-b276-179342bbaaee",
   "metadata": {},
   "source": [
    "# Quick preview (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74967021-0915-47ec-a4ee-6617b080da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preview_per_class(X: np.ndarray, y: np.ndarray, max_per_class: int = 5):\n",
    "    classes = np.unique(y)\n",
    "    for cls in classes:\n",
    "        idxs = np.where(y == cls)[0][:max_per_class]\n",
    "        if idxs.size == 0:\n",
    "            continue\n",
    "        plt.figure(figsize=(3 * len(idxs), 3))\n",
    "        for j, i in enumerate(idxs, start=1):\n",
    "            plt.subplot(1, len(idxs), j)\n",
    "            plt.imshow(X[i])\n",
    "            plt.title(str(cls))\n",
    "            plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "preview_per_class(X_u8, y_str, max_per_class=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd9215-abd4-429b-b115-3c57939c4e01",
   "metadata": {},
   "source": [
    "# Normalize to float32 [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8a984-fc51-4ffb-a3bc-b6d338fd2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X_u8.astype(np.float32) / 255.0)  # (N, H, W, 3) float32\n",
    "print(\"X:\", X.shape, X.dtype, f\"min={X.min():.3f}, max={X.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606187ca-6e7d-4a0b-9d65-10262aa65abb",
   "metadata": {},
   "source": [
    "# Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2725a-bb9a-4c68-a759-fe679c4f9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals, counts = np.unique(y_str, return_counts=True)\n",
    "for v, c in zip(unique_vals, counts):\n",
    "    print(f\"{v}: {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a4794-ba8f-4cb6-8bd0-824d8ac1f833",
   "metadata": {},
   "source": [
    "# Stratified split (Train / Val / Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cca6b7-3f6c-466b-91ea-805e809cbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train vs temp\n",
    "X_train, X_temp, y_train_str, y_temp_str = train_test_split(\n",
    "    X, y_str,\n",
    "    test_size=(1.0 - TRAIN_FRAC),\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_str\n",
    ")\n",
    "\n",
    "# Val vs Test from temp\n",
    "X_val, X_test, y_val_str, y_test_str = train_test_split(\n",
    "    X_temp, y_temp_str,\n",
    "    test_size=(1.0 - VAL_FRAC_OF_TEMP),\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_temp_str\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train_str.shape)\n",
    "print(\"Val  :\", X_val.shape,   y_val_str.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test_str.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa9c2dd-35be-439d-a3c6-90e14aa7e99f",
   "metadata": {},
   "source": [
    "# Build ONE label mapping from TRAIN, apply to all splits (fix critical bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bffaa-c28f-407f-9cde-98deb7851e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mapping only from TRAIN classes (stable and reproducible)\n",
    "classes = sorted(np.unique(y_train_str).tolist())\n",
    "label2idx = {lab: i for i, lab in enumerate(classes)}\n",
    "idx2label = {i: lab for lab, i in label2idx.items()}\n",
    "\n",
    "num_classes = len(classes)\n",
    "print(\"num_classes:\", num_classes)\n",
    "print(\"label2idx:\", label2idx)\n",
    "\n",
    "def encode_labels_onehot(y: np.ndarray, label2idx: dict[str, int], num_classes: int) -> np.ndarray:\n",
    "    idx = np.array([label2idx[v] for v in y], dtype=np.int64)\n",
    "    onehot = np.eye(num_classes, dtype=np.float32)[idx]\n",
    "    return onehot\n",
    "\n",
    "y_train = encode_labels_onehot(y_train_str, label2idx, num_classes)\n",
    "y_val   = encode_labels_onehot(y_val_str,   label2idx, num_classes)\n",
    "y_test  = encode_labels_onehot(y_test_str,  label2idx, num_classes)\n",
    "\n",
    "print(\"y_train:\", y_train.shape, y_train.dtype)\n",
    "print(\"y_val  :\", y_val.shape,   y_val.dtype)\n",
    "print(\"y_test :\", y_test.shape,  y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9eecf9-a70a-4a84-924a-23b2b2732e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save .npy (and optional label_mapping.csv)\n",
    "import csv\n",
    "\n",
    "# Save arrays\n",
    "np.save(OUT_NPY_DIR / \"x_train.npy\", X_train)\n",
    "np.save(OUT_NPY_DIR / \"y_train.npy\", y_train)\n",
    "\n",
    "np.save(OUT_NPY_DIR / \"x_valid.npy\", X_val)\n",
    "np.save(OUT_NPY_DIR / \"y_valid.npy\", y_val)\n",
    "\n",
    "np.save(OUT_NPY_DIR / \"x_test.npy\",  X_test)\n",
    "np.save(OUT_NPY_DIR / \"y_test.npy\",  y_test)\n",
    "\n",
    "print(\"[OK] Saved .npy files to:\", OUT_NPY_DIR)\n",
    "\n",
    "# Optional: save label mapping for reproducibility (recommended even for private data)\n",
    "mapping_path = OUT_NPY_DIR / \"label_mapping.csv\"\n",
    "with open(mapping_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"class_name\", \"class_index\"])\n",
    "    for lab, idx in label2idx.items():\n",
    "        w.writerow([lab, idx])\n",
    "\n",
    "print(\"[OK] Saved label mapping to:\", mapping_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
