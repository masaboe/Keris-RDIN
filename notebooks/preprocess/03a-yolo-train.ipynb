{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfcbc2c5",
   "metadata": {},
   "source": [
    "# YOLOv8 Training Notebook (Reproducible)\n",
    "\n",
    "This notebook trains and evaluates a YOLOv8 detector and organizes the workflow into:\n",
    "1) environment + imports, 2) dataset configuration, 3) sanity checks, 4) training, 5) evaluation + inference, and 6) export.\n",
    "\n",
    "**Reproducibility note:** dependencies should be declared in `requirements.txt` (or `pyproject.toml`), not installed inside this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdba90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Optional: pin a specific GPU (set to \"\" to let the framework decide)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ed89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Optional helpers for notebook display\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00627b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment diagnostics (recommended for appendices) ---\n",
    "import sys, platform\n",
    "import ultralytics\n",
    "\n",
    "print(\"Python      :\", sys.version.split()[0])\n",
    "print(\"Platform    :\", platform.platform())\n",
    "print(\"Ultralytics :\", ultralytics.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a522cb",
   "metadata": {},
   "source": [
    "## Dataset configuration\n",
    "\n",
    "Set `DATASET_ROOT` to the folder that contains `data.yaml` and YOLO-format splits, e.g.:\n",
    "\n",
    "```\n",
    "DATASET_ROOT/\n",
    "  data.yaml\n",
    "  train/images, train/labels\n",
    "  valid/images, valid/labels\n",
    "  test/images,  test/labels   (optional)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths (edit these two lines) ---\n",
    "DATASET_ROOT = Path(\"/workspace\")  # <- update to your dataset location\n",
    "YAML_FILE = DATASET_ROOT / \"data.yaml\"\n",
    "\n",
    "assert YAML_FILE.exists(), f\"data.yaml not found: {YAML_FILE}\"\n",
    "print(\"YAML_FILE:\", YAML_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience paths\n",
    "TRAIN_IMAGES = DATASET_ROOT / \"train\" / \"images\"\n",
    "TRAIN_LABELS = DATASET_ROOT / \"train\" / \"labels\"\n",
    "VAL_IMAGES   = DATASET_ROOT / \"valid\" / \"images\"\n",
    "VAL_LABELS   = DATASET_ROOT / \"valid\" / \"labels\"\n",
    "\n",
    "for p in [TRAIN_IMAGES, TRAIN_LABELS, VAL_IMAGES, VAL_LABELS]:\n",
    "    assert p.exists(), f\"Missing path: {p}\"\n",
    "\n",
    "print(\"Train images:\", TRAIN_IMAGES)\n",
    "print(\"Val images  :\", VAL_IMAGES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e36f6",
   "metadata": {},
   "source": [
    "## Model initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained checkpoint (edit as needed)\n",
    "PRETRAINED_WEIGHTS = Path(\"yolov8x.pt\")  # relative path inside repo\n",
    "\n",
    "model = YOLO(str(PRETRAINED_WEIGHTS))\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d1c42",
   "metadata": {},
   "source": [
    "## Dataset sanity checks\n",
    "- counts of images/labels\n",
    "- basic image size distribution\n",
    "- random visual inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(folder: Path):\n",
    "    exts = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n",
    "    return sorted([p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in exts])\n",
    "\n",
    "train_imgs = list_images(TRAIN_IMAGES)\n",
    "val_imgs   = list_images(VAL_IMAGES)\n",
    "\n",
    "print(f\"Train images: {len(train_imgs)}\")\n",
    "print(f\"Val images  : {len(val_imgs)}\")\n",
    "\n",
    "print(\"Train labels:\", len(list(TRAIN_LABELS.glob(\"*.txt\"))))\n",
    "print(\"Val labels  :\", len(list(VAL_LABELS.glob(\"*.txt\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a92b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_shapes(paths, max_items=200):\n",
    "    shapes = []\n",
    "    for p in paths[:max_items]:\n",
    "        im = cv2.imread(str(p), cv2.IMREAD_UNCHANGED)\n",
    "        if im is not None:\n",
    "            shapes.append(im.shape[:2])  # (H, W)\n",
    "    return shapes\n",
    "\n",
    "train_shapes = collect_image_shapes(train_imgs)\n",
    "val_shapes   = collect_image_shapes(val_imgs)\n",
    "\n",
    "def summarize_shapes(shapes, name):\n",
    "    if not shapes:\n",
    "        print(f\"{name}: no readable images\")\n",
    "        return\n",
    "    hs = [s[0] for s in shapes]\n",
    "    ws = [s[1] for s in shapes]\n",
    "    print(f\"{name}: sampled {len(shapes)} images\")\n",
    "    print(f\"  H: min={min(hs)} max={max(hs)} mean={np.mean(hs):.1f}\")\n",
    "    print(f\"  W: min={min(ws)} max={max(ws)} mean={np.mean(ws):.1f}\")\n",
    "\n",
    "summarize_shapes(train_shapes, \"Train\")\n",
    "summarize_shapes(val_shapes, \"Val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random visual inspection\n",
    "random.seed(0)\n",
    "\n",
    "sample_n = 15\n",
    "sample_paths = random.sample(train_imgs, k=min(sample_n, len(train_imgs)))\n",
    "\n",
    "plt.figure(figsize=(19, 12))\n",
    "for i, p in enumerate(sample_paths):\n",
    "    im = Image.open(p)\n",
    "    im = ImageOps.exif_transpose(im)\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(im)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Random training samples\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d2da6",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below is a reference training call.  \n",
    "Uncomment and run when you are ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PARAMS = dict(\n",
    "    data=str(YAML_FILE),\n",
    "    epochs=300,\n",
    "    imgsz=1024,\n",
    "    batch=16,\n",
    "    patience=20,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=5e-4,\n",
    "    lrf=0.01,\n",
    "    dropout=0.1,\n",
    "    device=0,\n",
    "    seed=42,\n",
    "    amp=True,\n",
    "    workers=4,\n",
    ")\n",
    "\n",
    "# results = model.train(**TRAIN_PARAMS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb6334",
   "metadata": {},
   "source": [
    "## Post-training: locate run directory\n",
    "\n",
    "Ultralytics typically writes to `runs/detect/train*`.  \n",
    "Set `RUN_DIR` to the run folder you want to analyze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca717f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = DATASET_ROOT / \"runs\" / \"detect\" / \"train\"  # update if using train2, train3, ...\n",
    "assert RUN_DIR.exists(), f\"Run directory not found: {RUN_DIR}\"\n",
    "\n",
    "# List artifacts\n",
    "for p in sorted(RUN_DIR.glob(\"*\")):\n",
    "    print(p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rgb(path: Path):\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Training summary plot\n",
    "results_png = RUN_DIR / \"results.png\"\n",
    "if results_png.exists():\n",
    "    img = read_rgb(results_png)\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Training summary (results.png)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"results.png not found in RUN_DIR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curves from results.csv (matplotlib only; no seaborn)\n",
    "results_csv = RUN_DIR / \"results.csv\"\n",
    "assert results_csv.exists(), f\"results.csv not found: {results_csv}\"\n",
    "\n",
    "df = pd.read_csv(results_csv)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "def plot_curve(y_train: str, y_val: str, title: str, ylim=None):\n",
    "    plt.figure(figsize=(10, 3.5))\n",
    "    plt.plot(df[\"epoch\"], df[y_train], label=\"train\")\n",
    "    plt.plot(df[\"epoch\"], df[y_val], label=\"val\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_curve(\"train/box_loss\", \"val/box_loss\", \"Box loss\")\n",
    "plot_curve(\"train/cls_loss\", \"val/cls_loss\", \"Classification loss\")\n",
    "plot_curve(\"train/dfl_loss\", \"val/dfl_loss\", \"DFL loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57885506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve images (if present)\n",
    "curve_files = {\n",
    "    \"P_curve.png\": \"Precision–confidence curve\",\n",
    "    \"R_curve.png\": \"Recall–confidence curve\",\n",
    "    \"F1_curve.png\": \"F1–confidence curve\",\n",
    "    \"PR_curve.png\": \"Precision–recall curve\",\n",
    "}\n",
    "\n",
    "present = [f for f in curve_files if (RUN_DIR / f).exists()]\n",
    "if not present:\n",
    "    print(\"No curve images found.\")\n",
    "else:\n",
    "    n = len(present)\n",
    "    cols = 2\n",
    "    rows = (n + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 5 * rows))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for ax, fname in zip(axes, present):\n",
    "        img = read_rgb(RUN_DIR / fname)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(curve_files[fname])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused axes\n",
    "    for ax in axes[len(present):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b936d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices (if present)\n",
    "cm_path = RUN_DIR / \"confusion_matrix.png\"\n",
    "cmn_path = RUN_DIR / \"confusion_matrix_normalized.png\"\n",
    "\n",
    "if cm_path.exists() and cmn_path.exists():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    axes[0].imshow(read_rgb(cm_path))\n",
    "    axes[0].set_title(\"Confusion matrix\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(read_rgb(cmn_path))\n",
    "    axes[1].set_title(\"Normalized confusion matrix\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Confusion matrix images not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be26fc9",
   "metadata": {},
   "source": [
    "## Evaluation & inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d023365",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = RUN_DIR / \"weights\" / \"best.pt\"\n",
    "assert best_weights.exists(), f\"best.pt not found: {best_weights}\"\n",
    "\n",
    "best_model = YOLO(str(best_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation on the validation split\n",
    "metrics = best_model.val(split=\"val\")\n",
    "\n",
    "metrics_df = pd.DataFrame.from_dict(metrics.results_dict, orient=\"index\", columns=[\"value\"])\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference grid on validation images\n",
    "val_paths = list_images(VAL_IMAGES)\n",
    "assert len(val_paths) > 0, f\"No images found in: {VAL_IMAGES}\"\n",
    "\n",
    "# pick evenly spaced samples\n",
    "k = 9\n",
    "idxs = np.linspace(0, len(val_paths) - 1, num=min(k, len(val_paths)), dtype=int)\n",
    "selected = [val_paths[i] for i in idxs]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 18))\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for ax, p in zip(axes, selected):\n",
    "    pred = best_model.predict(source=str(p), imgsz=1024, verbose=False)\n",
    "    annotated = pred[0].plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(annotated)\n",
    "    ax.set_title(p.name, fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "for ax in axes[len(selected):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450684a",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX (writes next to weights by default)\n",
    "best_model.export(format=\"onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
