{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c785859-e09e-4ae7-9914-1c34f42042b1",
   "metadata": {},
   "source": [
    "# Imports & GPU memory growth (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87919fd-a93f-4366-bfa3-6ddedf82cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "from typing import Optional\n",
    "\n",
    "# Optional TF GPU mem growth (only if TF is actually used later)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    print(f\"[INFO] TF GPUs: {len(gpus)} (memory growth enabled)\" if gpus else \"[INFO] TF GPUs: none\")\n",
    "except Exception as e:\n",
    "    print(f\"[INFO] TensorFlow not used / not available ({e})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6aa568-0c1e-42d3-99d3-320aad342458",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c618b4e-709f-4736-baad-1489027ff77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class AugConfig:\n",
    "    x_train_path: Path = Path(\"npyBilah/x_train.npy\")\n",
    "    y_train_path: Path = Path(\"npyBilah/y_train.npy\")\n",
    "\n",
    "    # If y is one-hot and the class order is reversed (last column = class 0), set True.\n",
    "    reverse_onehot: bool = False\n",
    "\n",
    "    # Geometry augmentation (white background)\n",
    "    shift_limit: float = 0.06\n",
    "    scale_limit: float = 0.06\n",
    "    rotate_limit: int = 5\n",
    "    perspective_scale: tuple = (0.02, 0.04)\n",
    "\n",
    "    # Mask extraction\n",
    "    white_thresh: int = 245\n",
    "\n",
    "    # Photometric (applied only on foreground mask)\n",
    "    brightness_limit: float = 0.2\n",
    "    contrast_limit: float = 0.2\n",
    "    blur_p: float = 0.2\n",
    "    blur_k: int = 3\n",
    "    noise_p: float = 0.2\n",
    "    noise_var: tuple = (10.0, 50.0)\n",
    "\n",
    "    # Aug strategy\n",
    "    aug_per_image: int = 2\n",
    "    balance_to_max: bool = True\n",
    "\n",
    "    # Size handling\n",
    "    expected_size: tuple = (512, 512)  # (H,W) expected; will resize if mismatch\n",
    "\n",
    "    # Random\n",
    "    seed: int = 42\n",
    "\n",
    "CFG = AugConfig()\n",
    "np.random.seed(CFG.seed)\n",
    "print(CFG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef601ac-9aa4-4c81-89a6-6db9a11edf16",
   "metadata": {},
   "source": [
    "# Label utilities (safe, consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5890c33-5b30-436a-85ee-70493752a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int_labels(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Accept integer labels or one-hot -> returns int labels.\"\"\"\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim > 1 and y.shape[-1] > 1:\n",
    "        return np.argmax(y, axis=1).astype(np.int32)\n",
    "    return y.astype(np.int32).reshape(-1)\n",
    "\n",
    "def maybe_reverse_labels(y_int: np.ndarray, num_classes: int, reverse: bool) -> np.ndarray:\n",
    "    \"\"\"Optional reverse mapping if the one-hot columns were reversed.\"\"\"\n",
    "    if not reverse:\n",
    "        return y_int\n",
    "    return (num_classes - 1) - y_int\n",
    "\n",
    "def to_onehot(y_int: np.ndarray, num_classes: int, reverse: bool) -> np.ndarray:\n",
    "    \"\"\"Convert int labels to one-hot; optionally reverse to match original column ordering.\"\"\"\n",
    "    if reverse:\n",
    "        # If original one-hot is reversed, we must reverse back for saving in that convention.\n",
    "        y_for_onehot = (num_classes - 1) - y_int\n",
    "    else:\n",
    "        y_for_onehot = y_int\n",
    "    return np.eye(num_classes, dtype=np.int32)[y_for_onehot]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c228b-216e-4c0f-9657-829a20eafa0b",
   "metadata": {},
   "source": [
    "# Image/mask utilities + photometric-on-mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdefcc3-6b49-458b-bca6-d65a58a69b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_u8_3ch_bgr(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Ensure uint8, 3-channel BGR for OpenCV.\"\"\"\n",
    "    arr = img\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        if arr.max() <= 1.0 + 1e-6:\n",
    "            arr = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr = np.round(arr).clip(0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        arr = arr.astype(np.uint8)\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        arr = cv2.cvtColor(arr, cv2.COLOR_GRAY2BGR)\n",
    "    elif arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = cv2.cvtColor(arr, cv2.COLOR_BGRA2BGR)\n",
    "    elif arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        pass\n",
    "    else:\n",
    "        arr = arr[:, :, :3]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def make_foreground_mask_from_white(img_u8_bgr: np.ndarray, white_thresh: int = 245) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Foreground mask (True = object) from near-white background.\n",
    "    Background if ALL channels >= white_thresh.\n",
    "    \"\"\"\n",
    "    b, g, r = cv2.split(img_u8_bgr)\n",
    "    bg = (b >= white_thresh) & (g >= white_thresh) & (r >= white_thresh)\n",
    "    mask = ~bg\n",
    "\n",
    "    mask_u8 = (mask.astype(np.uint8) * 255)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_OPEN, k)\n",
    "    mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "    return mask_u8 > 0\n",
    "\n",
    "\n",
    "def photometric_on_mask(\n",
    "    img_u8_bgr: np.ndarray,\n",
    "    mask_bool: np.ndarray,\n",
    "    brightness_limit: float = 0.2,\n",
    "    contrast_limit: float = 0.2,\n",
    "    blur_p: float = 0.2,\n",
    "    blur_k: int = 3,\n",
    "    noise_p: float = 0.2,\n",
    "    noise_var: tuple = (10.0, 50.0),\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply brightness/contrast/blur/noise only inside foreground mask.\n",
    "    Force background to pure white.\n",
    "    \"\"\"\n",
    "    out = img_u8_bgr.copy()\n",
    "\n",
    "    if mask_bool.any():\n",
    "        # Brightness/contrast\n",
    "        if np.random.rand() < 0.5:\n",
    "            alpha = 1.0 + np.random.uniform(-contrast_limit, contrast_limit)\n",
    "            beta = np.random.uniform(-brightness_limit, brightness_limit) * 255.0\n",
    "            adj = np.clip(out.astype(np.float32) * alpha + beta, 0, 255).astype(np.uint8)\n",
    "            out[mask_bool] = adj[mask_bool]\n",
    "\n",
    "        # Blur\n",
    "        if np.random.rand() < blur_p:\n",
    "            k = int(blur_k)\n",
    "            if k % 2 == 0:\n",
    "                k += 1\n",
    "            k = max(k, 3)\n",
    "            blr = cv2.GaussianBlur(out, (k, k), 0)\n",
    "            out[mask_bool] = blr[mask_bool]\n",
    "\n",
    "        # Noise\n",
    "        if np.random.rand() < noise_p:\n",
    "            var = np.random.uniform(noise_var[0], noise_var[1])\n",
    "            sigma = max(1e-6, np.sqrt(var))\n",
    "            noise = np.random.normal(0, sigma, out.shape).astype(np.float32)\n",
    "            ns = np.clip(out.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
    "            out[mask_bool] = ns[mask_bool]\n",
    "\n",
    "    out[~mask_bool] = 255\n",
    "    return out\n",
    "\n",
    "\n",
    "def post_to_original_dtype(img_u8_bgr: np.ndarray, ref: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert augmented uint8 BGR to match X_train dtype scale:\n",
    "      - if original is float in [0,1], output float in [0,1]\n",
    "      - else keep original dtype (usually uint8)\n",
    "    \"\"\"\n",
    "    is_float = np.issubdtype(ref.dtype, np.floating)\n",
    "    if is_float and ref.max() <= 1.0 + 1e-6:\n",
    "        return (img_u8_bgr.astype(np.float32) / 255.0).astype(ref.dtype)\n",
    "    return img_u8_bgr.astype(ref.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9a8f2-f7b3-4fdd-a0c1-12ba4b58a20c",
   "metadata": {},
   "source": [
    "# Albumentations geometry-only (white border) + single-step augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67aefb-699d-4ee2-b234-ee953f7f529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_geom = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=CFG.shift_limit,\n",
    "            scale_limit=CFG.scale_limit,\n",
    "            rotate_limit=CFG.rotate_limit,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=255,\n",
    "            mask_value=0,\n",
    "            p=0.7,\n",
    "        ),\n",
    "        A.Perspective(\n",
    "            scale=CFG.perspective_scale,\n",
    "            keep_size=True,\n",
    "            pad_mode=cv2.BORDER_CONSTANT,\n",
    "            pad_val=255,\n",
    "            mask_pad_val=0,\n",
    "            p=0.2,\n",
    "        ),\n",
    "    ],\n",
    "    additional_targets={\"mask\": \"mask\"},\n",
    ")\n",
    "\n",
    "def augment_once(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    One augmentation step:\n",
    "      - build foreground mask from white bg\n",
    "      - apply geometry transform to image & mask\n",
    "      - enforce white background after geometry\n",
    "      - apply photometric only on foreground\n",
    "      - resize to expected_size if needed\n",
    "    \"\"\"\n",
    "    img_u8 = ensure_u8_3ch_bgr(img)\n",
    "    mask0 = make_foreground_mask_from_white(img_u8, white_thresh=CFG.white_thresh)\n",
    "\n",
    "    data = augment_geom(image=img_u8, mask=(mask0.astype(np.uint8) * 255))\n",
    "    g_img = data[\"image\"]\n",
    "    g_mask = data[\"mask\"] > 0\n",
    "\n",
    "    # enforce white background (helps against interpolation artifacts)\n",
    "    g_img[~g_mask] = 255\n",
    "\n",
    "    out = photometric_on_mask(\n",
    "        g_img, g_mask,\n",
    "        brightness_limit=CFG.brightness_limit,\n",
    "        contrast_limit=CFG.contrast_limit,\n",
    "        blur_p=CFG.blur_p,\n",
    "        blur_k=CFG.blur_k,\n",
    "        noise_p=CFG.noise_p,\n",
    "        noise_var=CFG.noise_var,\n",
    "    )\n",
    "\n",
    "    H, W = CFG.expected_size\n",
    "    if out.shape[:2] != (H, W):\n",
    "        out = cv2.resize(out, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df5961-bc03-42c2-b3c9-131190b8e0b7",
   "metadata": {},
   "source": [
    "# Build augmented + balanced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ef705-1d45-4e1f-b29d-a224b59982b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "X_train = np.load(CFG.x_train_path)\n",
    "y_train = np.load(CFG.y_train_path)\n",
    "\n",
    "y_int = to_int_labels(y_train)\n",
    "num_classes = y_train.shape[-1] if (y_train.ndim > 1 and y_train.shape[-1] > 1) else int(y_int.max() + 1)\n",
    "\n",
    "# Optional reverse (ONLY if you know your one-hot ordering is reversed)\n",
    "y_int = maybe_reverse_labels(y_int, num_classes=num_classes, reverse=CFG.reverse_onehot)\n",
    "\n",
    "print(\"[INFO] num_classes:\", num_classes)\n",
    "print(\"[INFO] original distribution:\", Counter(y_int))\n",
    "\n",
    "class_counts = Counter(y_int)\n",
    "max_count = max(class_counts.values()) if class_counts else 0\n",
    "\n",
    "aug_images = []\n",
    "aug_labels = []\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    idx = np.where(y_int == cls)[0]\n",
    "    n = len(idx)\n",
    "    print(f\"\\n-- Class {cls}: {n} original sample(s)\")\n",
    "\n",
    "    if n == 0:\n",
    "        continue\n",
    "\n",
    "    # A) fixed aug_per_image\n",
    "    for i in idx:\n",
    "        for _ in range(CFG.aug_per_image):\n",
    "            out_u8 = augment_once(X_train[i])\n",
    "            aug_images.append(post_to_original_dtype(out_u8, X_train))\n",
    "            aug_labels.append(cls)\n",
    "\n",
    "    # B) balance to max_count (optional)\n",
    "    if CFG.balance_to_max:\n",
    "        current_total = n + (CFG.aug_per_image * n)\n",
    "        needed = max(0, max_count - current_total)\n",
    "\n",
    "        if needed > 0:\n",
    "            reps = int(np.ceil(needed / n))\n",
    "            count = 0\n",
    "            for _ in range(reps):\n",
    "                for i in idx:\n",
    "                    if count >= needed:\n",
    "                        break\n",
    "                    out_u8 = augment_once(X_train[i])\n",
    "                    aug_images.append(post_to_original_dtype(out_u8, X_train))\n",
    "                    aug_labels.append(cls)\n",
    "                    count += 1\n",
    "\n",
    "    print(f\"  -> added aug samples (so far): {len(aug_labels)}\")\n",
    "\n",
    "aug_images = np.asarray(aug_images, dtype=X_train.dtype)\n",
    "aug_labels = np.asarray(aug_labels, dtype=np.int32)\n",
    "\n",
    "X_train_bal = np.concatenate([X_train, aug_images], axis=0)\n",
    "y_train_bal_int = np.concatenate([y_int, aug_labels], axis=0)\n",
    "\n",
    "print(\"\\n[INFO] final distribution:\", Counter(y_train_bal_int))\n",
    "print(\"[INFO] X_train_bal:\", X_train_bal.shape, X_train_bal.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad6ea8-8889-4929-beaf-4d903def8b33",
   "metadata": {},
   "source": [
    "# Convert back to one-hot (matching original convention) + save (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377c58b-4e2a-491f-bedf-6ab6b529b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bal_onehot = to_onehot(y_train_bal_int, num_classes=num_classes, reverse=CFG.reverse_onehot)\n",
    "print(\"[INFO] y_train_bal_onehot:\", y_train_bal_onehot.shape, y_train_bal_onehot.dtype)\n",
    "\n",
    "# Optional save\n",
    "OUT_DIR = Path(\"npyBilah/aug\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(OUT_DIR / \"X_train_aug.npy\", X_train_bal)\n",
    "np.save(OUT_DIR / \"y_train_aug.npy\", y_train_bal_onehot)\n",
    "\n",
    "print(\"[OK] Saved:\", OUT_DIR / \"X_train_aug.npy\")\n",
    "print(\"[OK] Saved:\", OUT_DIR / \"y_train_aug.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25466d-14cf-464c-ac94-fbc8d2926cbd",
   "metadata": {},
   "source": [
    "# Preview 1 image/class → 8 augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e02d8-cfc7-4ae6-a9cb-cccb2adf0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr_to_rgb(img_bgr: np.ndarray) -> np.ndarray:\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def preview_augments_for_class(X: np.ndarray, y_int: np.ndarray, class_id: int, repeats: int = 8):\n",
    "    idx = np.where(y_int == class_id)[0]\n",
    "    if idx.size == 0:\n",
    "        print(f\"[SKIP] No samples for class {class_id}\")\n",
    "        return\n",
    "\n",
    "    j = np.random.choice(idx, 1, replace=False)[0]\n",
    "    orig_u8 = ensure_u8_3ch_bgr(X[j])\n",
    "    augs = [augment_once(orig_u8) for _ in range(repeats)]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    axes = axes.reshape(3, 3)\n",
    "\n",
    "    axes[0, 0].imshow(bgr_to_rgb(orig_u8))\n",
    "    axes[0, 0].set_title(\"Original\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    k = 0\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            if r == 0 and c == 0:\n",
    "                continue\n",
    "            axes[r, c].imshow(bgr_to_rgb(augs[k]))\n",
    "            axes[r, c].set_title(f\"Aug {k+1}\")\n",
    "            axes[r, c].axis(\"off\")\n",
    "            k += 1\n",
    "\n",
    "    plt.suptitle(f\"Class {class_id}: 1 sample → {repeats} augmentations\", y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "classes = sorted(np.unique(y_int).tolist())\n",
    "for cls in classes:\n",
    "    print(f\"\\n=== Class {cls} ===\")\n",
    "    preview_augments_for_class(X_train, y_int, cls, repeats=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca362b-724e-4e97-ad72-dc4fb4a16096",
   "metadata": {},
   "source": [
    "# Load .npy augment + per-class grid preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e88687-345a-4b5c-90e1-6d403a50ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "X_aug = np.load(\"npyBilah/aug/X_train_aug.npy\")\n",
    "y_aug = np.load(\"npyBilah/aug/y_train_aug.npy\")\n",
    "\n",
    "y_aug_int = to_int_labels(y_aug)\n",
    "# If the stored one-hot is reversed, convert it back to natural int order for analysis:\n",
    "y_aug_int = maybe_reverse_labels(y_aug_int, num_classes=y_aug.shape[-1], reverse=CFG.reverse_onehot)\n",
    "\n",
    "print(\"[INFO] AUG distribution:\", Counter(y_aug_int))\n",
    "\n",
    "def ensure_rgb_u8_for_show(img: np.ndarray) -> np.ndarray:\n",
    "    arr = img\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        if arr.max() <= 1.0 + 1e-6:\n",
    "            arr = (arr * 255.0).clip(0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr = np.round(arr).clip(0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        arr = arr.astype(np.uint8)\n",
    "\n",
    "    # assume BGR from pipeline\n",
    "    if arr.ndim == 2:\n",
    "        arr = cv2.cvtColor(arr, cv2.COLOR_GRAY2RGB)\n",
    "    elif arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)\n",
    "    elif arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = cv2.cvtColor(arr, cv2.COLOR_BGRA2RGB)\n",
    "    return arr\n",
    "\n",
    "rng = np.random.default_rng(CFG.seed)\n",
    "\n",
    "def show_aug_grid_for_class(cls_id: int, k: int = 8):\n",
    "    idx = np.where(y_aug_int == cls_id)[0]\n",
    "    if idx.size == 0:\n",
    "        print(f\"[SKIP] Class {cls_id}: no samples.\")\n",
    "        return\n",
    "\n",
    "    idxs = idx if idx.size <= k else rng.choice(idx, size=k, replace=False)\n",
    "    idxs = np.asarray(idxs)\n",
    "\n",
    "    rows = 2\n",
    "    cols = int(math.ceil(len(idxs) / rows))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2.2, rows * 2.2))\n",
    "    axes = np.array(axes).reshape(rows, cols)\n",
    "\n",
    "    for i in range(rows * cols):\n",
    "        r, c = divmod(i, cols)\n",
    "        ax = axes[r, c]\n",
    "        ax.axis(\"off\")\n",
    "        if i < len(idxs):\n",
    "            ax.imshow(ensure_rgb_u8_for_show(X_aug[idxs[i]]))\n",
    "            ax.set_title(f\"#{i+1}\", fontsize=9)\n",
    "\n",
    "    plt.suptitle(f\"AUG only — Class {cls_id} | shown {len(idxs)}\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for cls in sorted(np.unique(y_aug_int).tolist()):\n",
    "    show_aug_grid_for_class(cls, k=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
