{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook — ConvNeXt-Tiny (Baseline)\n",
    "\n",
    "This notebook trains and evaluates **ConvNeXt-Tiny (Baseline)** for the Keris image classification task.  \n",
    "It has been refactored for **reproducibility** and to serve as a clean **appendix artifact** for journal submission.\n",
    "\n",
    "## Recommended folder conventions\n",
    "- **Input data**: keep dataset paths configurable (see the *Configuration* cell).\n",
    "- **Outputs / artifacts**: write all run artifacts under `artifacts/03_convnext_tiny/` (created automatically below).\n",
    "\n",
    "## Reproducibility checklist\n",
    "- Fixed random seed (NumPy / framework seed)\n",
    "- Best-effort deterministic operations (may vary by GPU/driver)\n",
    "- Logged environment versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment & reproducibility (TensorFlow) ---\n",
    "import os, sys, platform, random\n",
    "import numpy as np\n",
    "\n",
    "SEED = int(os.environ.get(\"SEED\", \"42\"))\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ.setdefault(\"TF_DETERMINISTIC_OPS\", \"1\")  # best-effort determinism\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# GPU memory growth (safe default)\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"Python   :\", sys.version.split()[0])\n",
    "print(\"Platform :\", platform.platform())\n",
    "print(\"NumPy    :\", np.__version__)\n",
    "print(\"TF       :\", tf.__version__)\n",
    "print(\"GPUs     :\", gpus if gpus else \"None (CPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration (paths & artifact directory) ---\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root: by default, current working directory\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Edit these paths if needed\n",
    "DATA_ROOT = PROJECT_ROOT / \"dataset\"      # <-- set your dataset root here\n",
    "NPY_ROOT  = PROJECT_ROOT / \"npy\"          # <-- set your .npy root here (if used)\n",
    "\n",
    "# All outputs should go here\n",
    "ARTIFACT_DIR = PROJECT_ROOT / \"artifacts\" / \"03_convnext_tiny\"\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT :\", PROJECT_ROOT)\n",
    "print(\"DATA_ROOT    :\", DATA_ROOT)\n",
    "print(\"NPY_ROOT     :\", NPY_ROOT)\n",
    "print(\"ARTIFACT_DIR :\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & evaluation (original workflow)\n",
    "The cells below contain the original training pipeline with minimal functional changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcCX_UhLnFUV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# import efficientnet.keras as efn\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# from tensorflow.keras.applications.resnet import ResNet152\n",
    "# from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "X_train= \"x_train.npy\"\n",
    "X_test = \"x_test.npy\"\n",
    "X_val = \"x_valid.npy\"\n",
    "y_train= \"y_train_aug.npy\"\n",
    "y_test = \"y_test.npy\"\n",
    "y_val = \"y_valid.npy\"\n",
    "X_train = np.load(X_train)\n",
    "X_test = np.load(X_test)\n",
    "X_val = np.load(X_val)\n",
    "y_train = np.load(y_train)\n",
    "y_test = np.load(y_test)\n",
    "y_val = np.load(y_val)\n",
    "# seed_everything(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hitung jumlah class\n",
    "classes, counts = np.unique(y_train, axis=0, return_counts=True)\n",
    "\n",
    "# Print hasilnya\n",
    "print(\"Kelas: \", classes)\n",
    "print(\"Jumlah: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hitung jumlah class\n",
    "classes1, counts1 = np.unique(y_test, axis=0, return_counts=True)\n",
    "\n",
    "# Print hasilnya\n",
    "print(\"Kelas: \", classes1)\n",
    "print(\"Jumlah: \", counts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hitung jumlah class\n",
    "classes2, counts2 = np.unique(y_val, axis=0, return_counts=True)\n",
    "\n",
    "# Print hasilnya\n",
    "print(\"Kelas: \", classes2)\n",
    "print(\"Jumlah: \", counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts, counts1, counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "input_shape = X_train.shape[1:]        # (H,W,3) mis. 128x128x3\n",
    "target_size = (224, 224)\n",
    "\n",
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess\n",
    "\n",
    "def build_convnext_tiny_baseline(num_classes, input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Resizing(*target_size, name=\"resize_to_224\")(inputs)\n",
    "\n",
    "    # X kamu 0–1 float32 -> scale ke 0–255 untuk preprocess_input\n",
    "    x = layers.Lambda(lambda t: t * 255.0, name=\"scale_0_1_to_0_255\")(x)\n",
    "    x = layers.Lambda(convnext_preprocess, name=\"convnext_preprocess\")(x)\n",
    "\n",
    "    backbone = ConvNeXtTiny(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(*target_size, 3)\n",
    "    )\n",
    "    backbone.trainable = True  # baseline: langsung end-to-end (1 step), sesuai permintaan kamu\n",
    "\n",
    "    x = backbone(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # head sederhana seperti baseline kamu\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    return Model(inputs, outputs, name=\"Baseline_ConvNeXtTiny\")\n",
    "\n",
    "convnext_model = build_convnext_tiny_baseline(num_classes, input_shape)\n",
    "convnext_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, TopKCategoricalAccuracy\n",
    "\n",
    "# --- Class weights (sama persis) ---\n",
    "y_labels = np.argmax(y_train, axis=1)\n",
    "classes  = np.unique(y_labels)\n",
    "weights  = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_labels\n",
    ")\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# --- Focal loss (sama persis) ---\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
    "        fl = weight * cross_entropy\n",
    "        return tf.reduce_sum(fl, axis=-1)\n",
    "    return loss_fn\n",
    "\n",
    "loss_fn = focal_loss(alpha=0.25, gamma=2.0)\n",
    "\n",
    "# --- Optimizer & LR schedule (sama persis) ---\n",
    "learning_rate_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=5e-5,\n",
    "    decay_steps=100_000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "optimizer = Adam(\n",
    "    learning_rate=learning_rate_schedule,\n",
    "    clipnorm=1.0, beta_1=0.9, beta_2=0.999, epsilon=1e-7\n",
    ")\n",
    "\n",
    "# --- Compile metrics (sama persis) ---\n",
    "convnext_model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall'),\n",
    "        AUC(name='auc'),\n",
    "        TopKCategoricalAccuracy(k=3, name='top_3_acc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Callbacks (sama persis) ---\n",
    "lr_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_loss', mode='min',\n",
    "    patience=4, factor=0.5, min_lr=1e-6,\n",
    "    cooldown=2, verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min',\n",
    "    patience=8, restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        import time\n",
    "        self.start_time = time.time()\n",
    "    def on_train_end(self, logs=None):\n",
    "        import time\n",
    "        print(f\"Total training time: {time.time() - self.start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan y float32 (sesuai KerisRDNet)\n",
    "y_train_f = y_train.astype('float32')\n",
    "y_val_f   = y_val.astype('float32')\n",
    "\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    history = convnext_model.fit(\n",
    "        X_train, y_train_f,\n",
    "        batch_size=8,\n",
    "        epochs=100,\n",
    "        validation_data=(X_val, y_val_f),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[early_stop, TimeHistory()],\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "probs = convnext_model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc = (y_pred == y_true).mean()\n",
    "prec_macro = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "rec_macro  = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "f1_macro   = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "f1_weight  = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "try:\n",
    "    auc_ovr_macro = roc_auc_score(y_test, probs, multi_class=\"ovr\", average=\"macro\")\n",
    "except ValueError:\n",
    "    auc_ovr_macro = float(\"nan\")\n",
    "\n",
    "print(\"Accuracy          :\", acc)\n",
    "print(\"Precision (macro) :\", prec_macro)\n",
    "print(\"Recall (macro)    :\", rec_macro)\n",
    "print(\"F1 (macro)        :\", f1_macro)\n",
    "print(\"F1 (weighted)     :\", f1_weight)\n",
    "print(\"AUC (OVR macro)   :\", auc_ovr_macro)\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict using the model\n",
    "y_pred_probs = convnext_model.predict(X_test)  # Replace X_test with your test data\n",
    "\n",
    "# For binary classification, take the class with the highest probability (sigmoid output)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)  # If sigmoid, output is a probability, threshold at 0.5\n",
    "\n",
    "# For binary classification, y_test is already 1D, so no need for np.argmax()\n",
    "y_true = y_test  # Replace y_test with the ground truth labels\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')  # 'weighted' for handling class imbalances\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "ePURn6wAwVqu",
    "outputId": "3d763b42-46a8-44c7-92ad-90d006b085e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "loss, acc, prec, rec, auc, topk = convnext_model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Hitung F1-Score dengan benar, dan antisipasi pembagi nol\n",
    "if prec + rec > 0:\n",
    "    f1 = 2 * prec * rec / (prec + rec)\n",
    "else:\n",
    "    f1 = 0.0\n",
    "\n",
    "print(\"Loss       :\", loss)\n",
    "print(\"Accuracy   :\", acc)\n",
    "print(\"Precision  :\", prec)\n",
    "print(\"Recall     :\", rec)\n",
    "print(\"AUC        :\", auc)\n",
    "print(\"Top K        :\", topk)\n",
    "print(\"F1-Score   :\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzL4kXubwX3R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save(\"4-Resnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hitung jumlah class\n",
    "classes, counts = np.unique(y_test, axis=0, return_counts=True)\n",
    "\n",
    "# Print hasilnya\n",
    "print(\"Kelas: \", classes)\n",
    "print(\"Jumlah: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yB6r9S0Yoicx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Function to plot confusion matrix    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Predict probabilities dari model\n",
    "Y_pred_probs = convnext_model.predict(X_test)\n",
    "\n",
    "# 2. Konversi probabilitas ke label prediksi (multiclass)\n",
    "Y_pred_classes = np.argmax(Y_pred_probs, axis=1)\n",
    "\n",
    "# 3. Siapkan label sebenarnya\n",
    "# Jika y_test one-hot encoded, ubah ke indeks; \n",
    "# jika sudah 1D array, pakai langsung\n",
    "if y_test.ndim > 1 and y_test.shape[1] > 1:\n",
    "    Y_true = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    Y_true = y_test\n",
    "\n",
    "# 4. Hitung confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "# 5. Definisikan nama-nama class (ubah sesuai nama sebenarnya jika ada)\n",
    "class_labels = [f'class {i}' for i in range(27)]\n",
    "\n",
    "# 6. Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (27 Classes)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Tampilkan classification report\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (convnext_model, classification_report(\n",
    "            Y_true, \n",
    "            Y_pred_classes, \n",
    "            target_names=class_labels, \n",
    "            digits=4\n",
    "        )\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    # 1. Hitung report dan confusion matrix\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "\n",
    "    # 2. Jika binary classification, unpack TN, FP, FN, TP\n",
    "    if num_classes == 2:\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "        print(\"True Negatives :\", tn)\n",
    "        print(\"False Positives:\", fp)\n",
    "        print(\"False Negatives:\", fn)\n",
    "        print(\"True Positives :\", tp)\n",
    "    else:\n",
    "        # 3. Multiclass: print matrix dan per-class TP/FP/FN/TN\n",
    "        print(f\"Confusion Matrix ({num_classes} classes):\")\n",
    "        print(conf_matrix)\n",
    "        print(\"\\nPer-class metrics:\")\n",
    "        for i in range(num_classes):\n",
    "            tp = conf_matrix[i, i]\n",
    "            fp = conf_matrix[:, i].sum() - tp\n",
    "            fn = conf_matrix[i, :].sum() - tp\n",
    "            tn = conf_matrix.sum() - (tp + fp + fn)\n",
    "            print(f\" Class {i:2d} → TP={tp:4d}, FP={fp:4d}, FN={fn:4d}, TN={tn:4d}\")\n",
    "\n",
    "    # 4. DataFrame untuk classification report\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "    # 5. DataFrame untuk confusion matrix dengan label baris/kolom\n",
    "    class_labels = [f\"class_{i}\" for i in range(num_classes)]\n",
    "    df_conf_matrix = pd.DataFrame(\n",
    "        conf_matrix,\n",
    "        index=class_labels,\n",
    "        columns=class_labels\n",
    "    )\n",
    "\n",
    "    # 6. Tampilkan matrix sebagai DataFrame\n",
    "    print(\"\\nConfusion Matrix DataFrame:\")\n",
    "    print(df_conf_matrix)\n",
    "\n",
    "    return df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_classification_report(Y_true, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Ambil semua key dari history\n",
    "keys = list(history.history.keys())\n",
    "\n",
    "# 2. Cari key untuk accuracy (train) dan val_accuracy (val)\n",
    "#    Sesuaikan substring kalau metric Anda namanya 'categorical_accuracy' atau lain\n",
    "train_acc_key = next((k for k in keys if k == 'accuracy' or 'accuracy' in k and not k.startswith('val_')), None)\n",
    "val_acc_key   = next((k for k in keys if k.startswith('val_') and 'accuracy' in k), None)\n",
    "\n",
    "if train_acc_key is None or val_acc_key is None:\n",
    "    raise ValueError(f\"Metric accuracy tidak ditemukan di history.keys(): {keys}\")\n",
    "\n",
    "# 3. Plotting accuracy\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history[train_acc_key], label=f\"train ({train_acc_key})\")\n",
    "plt.plot(history.history[val_acc_key],   label=f\"val   ({val_acc_key})\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. (Opsional) Kalau mau plotting loss juga:\n",
    "if 'loss' in keys and 'val_loss' in keys:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history.history['loss'],     label='train (loss)')\n",
    "    plt.plot(history.history['val_loss'], label='val   (val_loss)')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[keys[2]])\n",
    "plt.plot(history.history[keys[8]])\n",
    "plt.title('Model Precision')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[keys[3]])\n",
    "plt.plot(history.history[keys[9]])\n",
    "plt.title('Model Recall')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[keys[1]])\n",
    "plt.plot(history.history[keys[7]])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[keys[4]])\n",
    "plt.plot(history.history[keys[10]])\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[keys[5]])\n",
    "plt.plot(history.history[keys[11]])\n",
    "plt.title('Top K Categorical Accuracy')\n",
    "plt.ylabel('top_3_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Ambil list history\n",
    "h = history.history\n",
    "\n",
    "# 2. Ambil precision & recall untuk train dan val\n",
    "train_prec = h['precision']\n",
    "train_rec  = h['recall']\n",
    "val_prec   = h['val_precision']\n",
    "val_rec    = h['val_recall']\n",
    "\n",
    "# 3. Hitung G-Mean: sqrt(precision * recall)\n",
    "gmean_train = [math.sqrt(p * r) for p, r in zip(train_prec, train_rec)]\n",
    "gmean_val   = [math.sqrt(p * r) for p, r in zip(val_prec,   val_rec)]\n",
    "\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(gmean_train, label='train G-Mean')\n",
    "plt.plot(gmean_val,   label='val   G-Mean')\n",
    "plt.title('Model G-Mean')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('G-Mean')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(30, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss', 'auc']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelh5__ = 'model.h5'\n",
    "convnext_model.save('model-h5/'+modelh5__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Keep dataset paths and output paths configurable for reproducibility.\n",
    "- If you publish this notebook, ensure no private paths or secrets are embedded.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOvWgVEKhpylpZviJkoIQr0",
   "name": "Resnet_skin_lesions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
